## transfer learning demo

图像风格迁移

### 准备数据

- [VGG19模型](http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat)，下载后放到`data`目录下
- 将风格图片`style.jpg`放到`data/image`文件夹下，将要处理的图片`content.jpg`放到`data/image`文件夹下，并且在`data`目录下新建`output`文件夹

### 训练模型
- 使用VGG中的一些层的输出来表示图片的内容特征和风格特征，使用`[‘conv4_2’,’conv5_2’]`表示内容特征，使用`[‘conv1_1’,’conv2_1’,’conv3_1’,’conv4_1’]`表示风格特征
- 将内容图片输入网络，计算内容图片在网络指定层（比如`[‘conv4_2’,’conv5_2’]`）上的输出值
- 计算内容损失
> 内容损失：内容图片在指定层上提取出的特征矩阵，与噪声图片在对应层上的特征矩阵的差值的L2范数。即求两两之间的像素差值的平方。
- 计算风格损失
> 风格损失可以定义为风格图像和噪音图像特征矩阵的格莱姆矩阵的差值的L2范数。
- 定义损失函数
> 损失函数为内容损失和风格损失的加权和。
- 训练模型
> 根据内容图片和噪声，生成一张噪声图片。并将噪声图片喂给网络，计算loss，再根据loss调整噪声图片。将调整后的图片喂给网络，重新计算loss，再调整，再计算…，直到达到指定迭代次数，此时，噪声图片已兼具内容图片的内容和风格图片的风格，进行保存即可。

### 操作步骤
- 在终端执行`python train.py`即可。
